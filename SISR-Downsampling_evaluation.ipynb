{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4fcecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bda17653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Images\n",
    "Directories = ['Set5', 'Set14', 'Urban100', 'BSD100', 'Celeba_HQ']\n",
    "scales = [2,3,4,8]\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "         \n",
    "        img = Image.open(folder + \"/\" + filename)\n",
    "        #img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c86dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample\n",
    "from PIL import Image \n",
    "import PIL \n",
    "\n",
    "def downsample(): \n",
    "    for directory in Directories:\n",
    "        images = load_images_from_folder('/Users/ege/Desktop/DataSets/' + directory + '/HR')\n",
    "        for scale in scales: \n",
    "            disk_dir = '/Users/ege/Desktop/DataSets/' + directory + \"/LR/\" + str(scale) + \"_b/\"\n",
    "            for i, oriimg in enumerate(images): \n",
    "                width, height = oriimg.size\n",
    "                #img = oriimg.resize((int(width/scale),int(height/scale)), Image.BICUBIC)\n",
    "                #img = cv2.resize(oriimg,None, fx=1/scale, fy=1/scale, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "                img.save(disk_dir +str(i)+ \".png\",\"PNG\")\n",
    "                print(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88806686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sewar.full_ref import mse, rmse, psnr, rmse_sw, uqi, ssim, ergas, scc, rase, sam, msssim, vifp, psnrb \n",
    "\n",
    "def evaluate(img1,img2):\n",
    "    print(ssim(img1,img2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b627682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample\n",
    "# Load Images \n",
    "\n",
    "Directories = ['Set5']\n",
    "scales = [2,3,4,8]\n",
    "\n",
    "def downsampling():\n",
    "    for directory in Directories:\n",
    "        for scale in scales: \n",
    "            images = load_images_from_folder('/Users/ege/Desktop/DataSets/' + directory + \"/LR/\" + str(scale) + \"_b\") \n",
    "            disk_dir = '/Users/ege/Desktop/DataSets/' + directory + \"/HR/\" + str(scale) + \"_upscaled/\"\n",
    "\n",
    "            #images = load_images_from_folder('/Users/ege/Desktop/DataSets/' + directory + '/HR')\n",
    "            for i, oriimg in enumerate(images): \n",
    "                width, height = oriimg.size\n",
    "                img = oriimg.resize((int(width*scale),int(height*scale)), Image.BICUBIC)\n",
    "                #img = cv2.resize(oriimg,None, fx=scale, fy=scale, interpolation = cv2.INTER_CUBIC)\n",
    "                img.save(disk_dir +str(i)+ \".png\",\"PNG\")\n",
    "                print(img.size)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "19d4e478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder:3_upscaled image number:0\n",
      "Folder:3_upscaled image number:1\n",
      "Folder:3_upscaled image number:3\n",
      "Folder:3_upscaled image number:4\n",
      "Folder:8_upscaled image number:1\n",
      "Folder:2_upscaled image number:0\n",
      "Folder:2_upscaled image number:1\n",
      "Folder:2_upscaled image number:2\n",
      "Folder:2_upscaled image number:3\n",
      "Folder:2_upscaled image number:4\n",
      "Folder:2_upscaled image number:5\n",
      "Folder:2_upscaled image number:6\n",
      "Folder:2_upscaled image number:7\n",
      "Folder:2_upscaled image number:8\n",
      "Folder:2_upscaled image number:10\n",
      "Folder:2_upscaled image number:11\n",
      "Folder:2_upscaled image number:12\n",
      "Folder:2_upscaled image number:13\n",
      "Folder:3_upscaled image number:0\n",
      "Folder:3_upscaled image number:1\n",
      "Folder:3_upscaled image number:2\n",
      "Folder:3_upscaled image number:3\n",
      "Folder:3_upscaled image number:4\n",
      "Folder:3_upscaled image number:5\n",
      "Folder:3_upscaled image number:6\n",
      "Folder:3_upscaled image number:7\n",
      "Folder:3_upscaled image number:8\n",
      "Folder:3_upscaled image number:9\n",
      "Folder:3_upscaled image number:10\n",
      "Folder:3_upscaled image number:11\n",
      "Folder:3_upscaled image number:12\n",
      "Folder:3_upscaled image number:13\n",
      "Folder:4_upscaled image number:0\n",
      "Folder:4_upscaled image number:1\n",
      "Folder:4_upscaled image number:2\n",
      "Folder:4_upscaled image number:3\n",
      "Folder:4_upscaled image number:4\n",
      "Folder:4_upscaled image number:5\n",
      "Folder:4_upscaled image number:6\n",
      "Folder:4_upscaled image number:7\n",
      "Folder:4_upscaled image number:8\n",
      "Folder:4_upscaled image number:10\n",
      "Folder:4_upscaled image number:11\n",
      "Folder:4_upscaled image number:12\n",
      "Folder:4_upscaled image number:13\n",
      "Folder:8_upscaled image number:0\n",
      "Folder:8_upscaled image number:1\n",
      "Folder:8_upscaled image number:2\n",
      "Folder:8_upscaled image number:3\n",
      "Folder:8_upscaled image number:4\n",
      "Folder:8_upscaled image number:5\n",
      "Folder:8_upscaled image number:6\n",
      "Folder:8_upscaled image number:7\n",
      "Folder:8_upscaled image number:8\n",
      "Folder:8_upscaled image number:10\n",
      "Folder:8_upscaled image number:11\n",
      "Folder:8_upscaled image number:12\n",
      "Folder:8_upscaled image number:13\n",
      "(76, 14)\n",
      "          0        0      0  0   0            0          0          0  \\\n",
      "0   bicubic  bicubic   Set5  2   0    17.842459   4.224034  35.616256   \n",
      "1   bicubic  bicubic   Set5  2   1    53.836402   7.337329  30.820043   \n",
      "2   bicubic  bicubic   Set5  2   2    21.177931   4.601949  34.871968   \n",
      "3   bicubic  bicubic   Set5  2   3   159.013072  12.610039  26.116475   \n",
      "4   bicubic  bicubic   Set5  2   4    45.938278   6.777778  31.509056   \n",
      "..      ...      ...    ... ..  ..          ...        ...        ...   \n",
      "71  bicubic  bicubic  Set14  8   9  6703.562572  81.875287   9.867747   \n",
      "72  bicubic  bicubic  Set14  8  10          NaN        NaN        NaN   \n",
      "73  bicubic  bicubic  Set14  8  11          NaN        NaN        NaN   \n",
      "74  bicubic  bicubic  Set14  8  12          NaN        NaN        NaN   \n",
      "75  bicubic  bicubic  Set14  8  13          NaN        NaN        NaN   \n",
      "\n",
      "           0         1          0         0                   0         0  \n",
      "0   0.961902  0.961918  35.343053  0.027777  0.990274+0.000000j  0.027777  \n",
      "1   0.962697  0.962728  30.782827  0.052793  0.990593+0.000000j  0.052793  \n",
      "2   0.976846  0.976938  34.796345  0.062516  0.993266+0.000000j  0.062516  \n",
      "3   0.938030  0.938053  26.060397  0.104154  0.983887+0.000000j  0.104154  \n",
      "4   0.860378  0.860418  31.033519  0.068697  0.977031+0.000000j  0.068697  \n",
      "..       ...       ...        ...       ...                 ...       ...  \n",
      "71  0.188719  0.253519   9.832960  0.625848  0.078499+0.034940j  0.625848  \n",
      "72       NaN       NaN        NaN       NaN N00000000a00000000N       NaN  \n",
      "73       NaN       NaN        NaN       NaN N00000000a00000000N       NaN  \n",
      "74       NaN       NaN        NaN       NaN N00000000a00000000N       NaN  \n",
      "75       NaN       NaN        NaN       NaN N00000000a00000000N       NaN  \n",
      "\n",
      "[76 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read and evaluate\n",
    "Directories = ['Set5','Set14']\n",
    "scales = [2,3,4,8]#,3,4,8]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sewar.full_ref import mse, rmse, psnr, rmse_sw, uqi, ssim, ergas, scc, rase, sam, msssim, vifp, psnrb \n",
    "\n",
    "metric_name = []\n",
    "upsampling_method = []\n",
    "downsampling_method = []\n",
    "image_set = []\n",
    "image_scale = [] \n",
    "image_number = []\n",
    "metric_1 = []\n",
    "metric_2 = []\n",
    "metric_3 = []\n",
    "metric_4 = []\n",
    "metric_5 = []\n",
    "metric_6 = []\n",
    "metric_7 = []\n",
    "metric_8 = []\n",
    "\n",
    "for directory in Directories:    \n",
    "    for scale in scales: \n",
    "        images_1 = load_images_from_folder('/Users/ege/Desktop/DataSets/' + directory + \"/HR/\" + \"Original\") \n",
    "        images_2 =  load_images_from_folder('/Users/ege/Desktop/DataSets/' + directory + \"/HR/\" + str(scale) + \"_upscaled/\")\n",
    "\n",
    "        #images = load_images_from_folder('/Users/ege/Desktop/DataSets/' + directory + '/HR')\n",
    "        for i, oriimg in enumerate(images_1): \n",
    "            #evaluated_value = ssim(oriimg,images_2[i]) #evaluate(oriimg,images_2[i])\n",
    "            #value_mse = uqi(images_1[i],images_2[i])\n",
    "            #print(value_mse)\n",
    "            \n",
    "            pil_image_1 = images_1[i].convert('RGB') \n",
    "            pil_image_2 = images_2[i].convert('RGB')\n",
    "            \n",
    "            open_cv_image_1 = np.array(pil_image_1) \n",
    "            open_cv_image_2 = np.array(pil_image_2) \n",
    "            \n",
    "            # Convert RGB to BGR \n",
    "            open_cv_image_1 = open_cv_image_1[:, :, ::-1].copy()\n",
    "            open_cv_image_2 = open_cv_image_2[:, :, ::-1].copy()\n",
    "            \n",
    "            try:\n",
    "                mse_value = mse(open_cv_image_1,open_cv_image_2) #evaluate(oriimg,images_2[i])\n",
    "                rmse_value = rmse(open_cv_image_1,open_cv_image_2)\n",
    "                psnr_value = psnr(open_cv_image_1,open_cv_image_2)\n",
    "                rmse_sw_value = rmse_sw(open_cv_image_1,open_cv_image_2)\n",
    "                ssim_value = ssim(open_cv_image_1,open_cv_image_2)\n",
    "                sam_value = sam(open_cv_image_1,open_cv_image_2)\n",
    "                msssim_value = msssim(open_cv_image_1,open_cv_image_2)\n",
    "                psnrb_value = psnrb(open_cv_image_1,open_cv_image_2) \n",
    "                \n",
    "            except:\n",
    "                mse_value = None\n",
    "                rmse_value = None\n",
    "                psnr_value = None\n",
    "                ssim_value = None\n",
    "                sam_value = None\n",
    "                msssim_value = None\n",
    "                psnrb_value = None\n",
    "                \n",
    "                print('Folder:' + str(scale) + '_upscaled image number:' + str(i))\n",
    "                pass\n",
    "            \n",
    "\n",
    "            # Merge all the lists/Pandas Dataframes in one and then concatenate them as a LIST\n",
    "            upsampling_method.append('bicubic')\n",
    "            downsampling_method.append('bicubic')\n",
    "            image_set.append(str(directory))\n",
    "            image_scale.append(str(scale))\n",
    "            image_number.append(str(i))\n",
    "            metric_1.append(mse_value)\n",
    "            metric_2.append(rmse_value)\n",
    "            metric_3.append(psnr_value)\n",
    "            metric_4.append(ssim_value)\n",
    "            metric_5.append(psnrb_value)\n",
    "            metric_6.append(sam_value)\n",
    "            metric_7.append(msssim_value)\n",
    "            metric_8.append(sam_value)\n",
    "            \n",
    "\n",
    "            \n",
    "d_1 =  pd.DataFrame(metric_1)\n",
    "d_2 =  pd.DataFrame(metric_2)\n",
    "d_3 =  pd.DataFrame(metric_3)\n",
    "d_4 =  pd.DataFrame(metric_4)\n",
    "d_5 =  pd.DataFrame(metric_5)\n",
    "d_6 =  pd.DataFrame(metric_6)\n",
    "d_7 =  pd.DataFrame(metric_7)\n",
    "d_8 =  pd.DataFrame(metric_8)\n",
    "m_1 =  pd.DataFrame(upsampling_method)\n",
    "m_2 =  pd.DataFrame(downsampling_method)\n",
    "i_s =  pd.DataFrame(image_set)\n",
    "i_m =  pd.DataFrame(image_scale)\n",
    "i_n =  pd.DataFrame(image_number)\n",
    "\n",
    "\n",
    "        \n",
    "frames = [m_1,m_2,i_s,i_m,i_n,d_1,d_2,d_3,d_4,d_5,d_6,d_7,d_8]\n",
    "result = pd.concat(frames, axis=1)\n",
    "\n",
    "            # Save the big LIST again as Dataframe and then save it as list_2.csv\n",
    "df = pd.DataFrame(result)\n",
    "print(df.shape)\n",
    "print(df)\n",
    "df.to_csv('first_evaluation_test.csv', mode='a', header=False)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f33f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare https://github.com/andrewekhalel/sewar\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
